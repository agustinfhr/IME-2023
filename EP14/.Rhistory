sample_n(300)
ggplot(muestra, aes(x=ytotcorh)) +
geom_histogram(binwidth = 1000) # Ajusta el valor de 'binwidth' de acuerdo a tus datos
View(muestra)
View(poblacion)
View(poblacion)
p_completo <- muestra %>% filter(educ == "Profesional Completo")
p_incompleto <- muestra %>% filter(educ == "Profesional Incompleto")
dir <- "C:/Users/agust/Desktop/Repo IME/IME-2023/EP11"
basename <- "EP11 Datos.csv"
file <- file.path(dir, basename)
poblacion <- read.csv2(file = file)
p_completo <- poblacion %>% filter(educ == "Profesional Completo")
p_incompleto <- poblacion %>% filter(educ == "Profesional Incompleto")
# Muestra aleatoria de 300 datos
set.seed(123) # Esto asegura la reproducibilidad de tus resultados
muestra_p_completo <- p_completo %>%
sample_n(300)
# Muestra aleatoria de 300 datos
set.seed(123) # Esto asegura la reproducibilidad de tus resultados
muestra_p_incompleto <- p_incompleto %>%
sample_n(300)
par(mfrow=c(1,2)) # Permite que los dos gráficos se muestren en la misma fila
qqnorm(muestra_p_completo$ytotcorh, main = "Gráfico Q-Q para Profesional Completo")
qqline(muestra_p_completo$ytotcorh, col = "red")
qqnorm(muestra_p_incompleto$ytotcorh, main = "Gráfico Q-Q para Profesional Incompleto")
qqline(muestra_p_incompleto$ytotcorh, col = "red")
shapiro.test(muestra_p_completo$ytotcorh)
shapiro.test(muestra_p_incompleto$ytotcorh)
dir <- "C:/Users/agust/Desktop/Repo IME/IME-2023/EP11"
basename <- "EP11 Datos.csv"
file <- file.path(dir, basename)
poblacion <- read.csv2(file = file)
p_completo <- poblacion %>% filter(educ == "Profesional Completo")
p_incompleto <- poblacion %>% filter(educ == "Profesional Incompleto")
# Muestra aleatoria de 300 datos
set.seed(123) # Esto asegura la reproducibilidad de tus resultados
muestra_p_completo <- p_completo %>%
sample_n(30)
# Muestra aleatoria de 300 datos
set.seed(123) # Esto asegura la reproducibilidad de tus resultados
muestra_p_incompleto <- p_incompleto %>%
sample_n(30)
# Crear un gráfico Q-Q para 'ytotcorh' en cada subconjunto de datos
par(mfrow=c(1,2)) # Permite que los dos gráficos se muestren en la misma fila
qqnorm(muestra_p_completo$ytotcorh, main = "Gráfico Q-Q para Profesional Completo")
qqline(muestra_p_completo$ytotcorh, col = "red")
qqnorm(muestra_p_incompleto$ytotcorh, main = "Gráfico Q-Q para Profesional Incompleto")
qqline(muestra_p_incompleto$ytotcorh, col = "red")
shapiro.test(muestra_p_completo$ytotcorh)
shapiro.test(muestra_p_incompleto$ytotcorh)
# ------------------------------------------------------------------------------
# 2. Propongan una pregunta de investigación original, que involucre la comparación de las medias de más de
# dos grupos independientes (más abajo se dan unos ejemplos). Fijando una semilla distinta a la anterior,
# seleccionen una muestra aleatoria de hogares (400 < n < 600) y respondan la pregunta propuesta utilizando
# bootstrapping. Solo por ejercicio académico, aplique un análisis post-hoc con bootstrapping aunque este no
# sea necesario.
if (!require(boot)) {
install.packages("boot", dependencies = TRUE )
require (boot)
}
if (!require(simpleboot)) {
install.packages("simpleboot", dependencies = TRUE )
require (simpleboot)
}
set.seed(1784)
n <- 500
Ingresos_Media <- select(datos_casen %>% filter(educ == "M. Hum. Completa"), contains("ytot"))
# ------------------------------- DATOS ----------------------------------------
dir <- "C:/Users/rowin/OneDrive/Escritorio/modelos estadistico/grupo_3.2/EP11"
basename <- "EP11 Datos.csv"
file <- file.path(dir, basename)
poblacion <- read.csv2(file = file)
# ------------------------------- DATOS ----------------------------------------
dir <- "C:/Users/agust/Desktop/Repo IME/IME-2023/EP11"
basename <- "EP11 Datos.csv"
file <- file.path(dir, basename)
poblacion <- read.csv2(file = file)
set.seed(1784)
n <- 500
Ingresos_Media <- select(datos_casen %>% filter(educ == "M. Hum. Completa"), contains("ytot"))
set.seed(1784)
n <- 500
Ingresos_Media <- select(poblacion %>% filter(educ == "M. Hum. Completa"), contains("ytot"))
Ingresos_Tecnico <- select(poblacion %>% filter(educ == "Técnico Nivel Superior Completo"), contains("ytot") )
Ingresos_Profesional <- select(poblacion %>% filter(educ == "Profesional Completo"), contains("ytot"))
Ingresos_Media <- select(poblacion %>% filter(educ == "M. Hum. Completa"), contains("ytot"))
Ingresos_Tecnico <- select(poblacion %>% filter(educ == "Tecnico Nivel Superior Completo"), contains("ytot") )
Ingresos_Profesional <- select(poblacion %>% filter(educ == "Profesional Completo"), contains("ytot"))
#Se muestrean los ingresos según el nivel de estudios
m_Media <- sample(Ingresos_Media$ytotcorh, n)
m_Tecnico <- sample(Ingresos_Tecnico$ytotcorh, n)
m_Profesional <- sample(Ingresos_Profesional$ytotcorh, n)
# Comprobar normalidad de las muestras .
print (shapiro.test(m_Media))
print (shapiro.test(m_Tecnico))
print (shapiro.test(m_Profesional))
educ <- c ( rep("Media", n), rep("Tecnico",n), rep("Profesional", n))
Ingresos <- c(m_Media, m_Tecnico, m_Profesional)
datos <- data.frame(Ingresos, educ)
# Calcular la diferencia observada entre las medias muestrales.
media_Media <- mean(m_Media)
media_Tecnico <- mean(m_Tecnico)
media_Profesional <- mean(m_Profesional)
cat ("diferencia Media - Tecnico:", media_Media - media_Tecnico, "\n\n" )
cat ("diferencia Media - Profesional:", media_Media - media_Profesional, "\n\n" )
cat ("diferencia Tecnico - Profesional:", media_Tecnico - media_Profesional, "\n\n" )
# Establecer el nivel de significación.
alfa <- 0.05
# Crear la distribución Bootstrap.
B <- 9999
# Distribución Bootstrap entre el nivel de educación Media y Técnico.
distribucion_bootstrap_Media_Tecnico <- two.boot(m_Media, m_Tecnico, FUN = mean, R = B)
valores <- data.frame(distribucion_bootstrap_Media_Tecnico$t)
colnames(valores) <- "valores"
graficar_distribucion(valores$valores)
# Distribución Bootstrap entre el nivel de educación Media y Técnico.
distribucion_bootstrap_Media_Tecnico <- two.boot(m_Media, m_Tecnico, FUN = mean, R = B)
valores <- data.frame(distribucion_bootstrap_Media_Tecnico$t)
colnames(valores) <- "valores"
graficar_distribucion(valores$valores)
# Función para graficar una distribución.
# Argumentos :
# - distribucion : distribución nula del estadístico de interés.
# - ...: otros argumentos a ser entregados a gghistogram y ggqqplot .
graficar_distribucion <- function(distribucion, ...) {
observaciones <- data.frame(distribucion)
histograma <- gghistogram(observaciones, x = "distribucion",
xlab = "Estadístico de interés",
ylab = "Frecuencia", ...)
qq <- ggqqplot(observaciones , x = "distribucion", ...)
# Crear una única figura con todos los gráficos de dispersión.
figura <- ggarrange(histograma, qq ,ncol = 2 , nrow = 1)
print(figura)
}
# Distribución Bootstrap entre el nivel de educación Media y Técnico.
distribucion_bootstrap_Media_Tecnico <- two.boot(m_Media, m_Tecnico, FUN = mean, R = B)
valores <- data.frame(distribucion_bootstrap_Media_Tecnico$t)
colnames(valores) <- "valores"
graficar_distribucion(valores$valores)
cat("Distribución bootstrap:\n" )
cat("\tMedia:", mean(valores$valores), "\n")
cat("\tDesviación estándar:", sd(valores$valores), "\n\n")
#Construir el intervalo de confianza.
#Construir el intervalo de confianza.
intervalo_M_T <- boot.ci(distribucion_bootstrap_Media_Tecnico, conf = 1-alfa,
type = "bca")
print ( intervalo_M_T )
# Distribución Bootstrap entre el nivel de educación Media y Profesional.
distribucion_bootstrap_Media_Profesional <- two.boot(m_Media, m_Profesional, FUN = mean, R = B)
valores <- data.frame(distribucion_bootstrap_Media_Profesional$t)
colnames(valores) <- "valores"
graficar_distribucion(valores$valores)
cat("Distribución bootstrap:\n" )
cat("\tMedia:", mean(valores$valores), "\n")
cat("\tDesviación estándar:", sd(valores$valores), "\n\n")
#Construir el intervalo de confianza.
intervalo_M_P <- boot.ci(distribucion_bootstrap_Media_Profesional, conf = 1-alfa,
type = "bca")
print (intervalo_M_P)
# Distribución Bootstrap entre el nivel de educación Técnico y Profesional.
distribucion_bootstrap_Tecnico_Profesional <- two.boot(m_Tecnico, m_Profesional, FUN = mean, R = B)
valores <- data.frame(distribucion_bootstrap_Tecnico_Profesional$t)
colnames(valores) <- "valores"
graficar_distribucion(valores$valores)
cat("Distribución bootstrap:\n" )
cat("\tMedia:", mean(valores$valores), "\n")
cat("\tDesviación estándar:", sd(valores$valores), "\n\n")
#Construir el intervalo de confianza.
intervalo_T_P <- boot.ci(distribucion_bootstrap_Tecnico_Profesional, conf = 1-alfa,
type = "bca")
print(intervalo_T_P)
#Intervalos de confianza para cada una de las distribuciones Bootstrap
print("Intervalos de confianza:")
print(intervalo_M_T)
print(intervalo_M_P)
print(intervalo_T_P)
# Análisis post - hoc .
# Función para calcular la media de las diferencias para dos columnas de una
# matriz de datos en formato ancho .
media_diferencias <- function(datos , columna_1 , columna_2) {
media <- mean(datos[[columna_1]] - datos[[ columna_2]])
return ( media )
}
# Función para generar la distribuciones de la diferencia de medias a
# partir de las permutaciones .
distribucion_diferencias <- function ( permutaciones , columna_1, columna_2, n) {
R <- n
distribucion <- c ()
for ( i in 1: R ) {
datos <- permutaciones[i,]
diferencia <- media_diferencias(datos, columna_1, columna_2)
distribucion <- c(distribucion, diferencia )
}
return ( distribucion )
}
if (!require(tidyverse ) ) {
install.packages("tidyverse ", dependencies = TRUE )
require (tidyverse )
}
Instancia <- factor (1:n)
datos_anchos <- data.frame(Instancia, Media = m_Media, Tecnico = m_Tecnico, Profesional = m_Profesional)
datos_largos <- datos_anchos %>% pivot_longer(c("Media", "Tecnico" ,
"Profesional"),
names_to = "Educación" ,
values_to = "Ingresos" )
datos_largos[["Educación"]] <- factor(datos_largos[["Educación" ]])
n<- nrow(datos_anchos)
dif_Media_Tecnico <- distribucion_diferencias(datos_anchos, "Media", "Tecnico", n)
dif_Media_Profesional <- distribucion_diferencias(datos_anchos, "Media" , "Profesional", n)
dif_Tecnico_Profesional <- distribucion_diferencias(datos_anchos, "Tecnico", "Profesional", n)
# Obtener valores p.
# Función para generar la distribuciones de la diferencia de medias a
# partir de las permutaciones .
distribucion_diferencias <- function ( permutaciones , columna_1, columna_2, n) {
R <- n
distribucion <- c ()
for ( i in 1: R ) {
datos <- permutaciones[i,]
diferencia <- media_diferencias(datos, columna_1, columna_2)
distribucion <- c(distribucion, diferencia )
}
return ( distribucion )
}
if (!require(tidyverse ) ) {
install.packages("tidyverse ", dependencies = TRUE )
require (tidyverse )
}
Instancia <- factor (1:n)
datos_anchos <- data.frame(Instancia, Media = m_Media, Tecnico = m_Tecnico, Profesional = m_Profesional)
datos_largos <- datos_anchos %>% pivot_longer(c("Media", "Tecnico" ,
"Profesional"),
names_to = "Educación" ,
values_to = "Ingresos" )
datos_largos[["Educación"]] <- factor(datos_largos[["Educación" ]])
n<- nrow(datos_anchos)
dif_Media_Tecnico <- distribucion_diferencias(datos_anchos, "Media", "Tecnico", n)
dif_Media_Profesional <- distribucion_diferencias(datos_anchos, "Media" , "Profesional", n)
dif_Tecnico_Profesional <- distribucion_diferencias(datos_anchos, "Tecnico", "Profesional", n)
# Obtener valores p.
# Calcula el valor p de las diferencias usando la prueba t
p_Media_Tecnico <- t.test(datos_anchos$Media, datos_anchos$Tecnico, alternative = "two.sided", var.equal = TRUE)$p.value
p_Media_Profesional <- t.test(datos_anchos$Media, datos_anchos$Profesional, alternative = "two.sided", var.equal = TRUE)$p.value
p_Tecnico_Profesional <- t.test(datos_anchos$Tecnico, datos_anchos$Profesional, alternative = "two.sided", var.equal = TRUE)$p.value
# Muestra los valores p
cat("Valor p de la diferencia entre Media y Tecnico: ", p_Media_Tecnico, "\n")
cat("Valor p de la diferencia entre Media y Profesional: ", p_Media_Profesional, "\n")
cat("Valor p de la diferencia entre Tecnico y Profesional: ", p_Tecnico_Profesional, "\n")
dif_Media_Tecnico <- distribucion_diferencias(datos_anchos, "Media", "Tecnico", n)
dif_Media_Profesional <- distribucion_diferencias(datos_anchos, "Media" , "Profesional", n)
dif_Tecnico_Profesional <- distribucion_diferencias(datos_anchos, "Tecnico", "Profesional", n)
# Obtener valores p.
# Muestra los valores p
cat("Valor p de la diferencia entre Media y Tecnico: ", dif_Media_Tecnico, "\n")
cat("Valor p de la diferencia entre Media y Profesional: ", dif_Media_Profesional, "\n")
cat("Valor p de la diferencia entre Tecnico y Profesional: ", dif_Tecnico_Profesional, "\n")
# ------------------------------- DATOS ----------------------------------------
# Primero, necesitamos cargar los datos en R. Asumamos que los datos están en dos vectores.
Winter_Nelly <- c(213.41, 185.9876, 221.9353, 320.1673, 201.3828, 180.1779, 168.4547, 222.9346, 183.4629)
Golden_Bosc <- c(170.8754, 144.3119, 166.2316, 114.3064, 112.9957, 126.6177, 117.5733, 128.7313, 143.4207, 210.4415, 138.7852, 272.3915)
# A continuación, es útil visualizar los datos. Podemos hacer esto con un boxplot.
boxplot(Winter_Nelly, Golden_Bosc, main = "Comparación de pesos", xlab = "Variedad de pera", ylab = "Peso en gramos", names = c("Winter Nelly", "Golden Bosc"))
boxplot(Winter_Nelly, Golden_Bosc,
main = "Comparación de pesos",
xlab = "Variedad de pera",
ylab = "Peso en gramos",
names = c("Winter Nelly", "Golden Bosc"))
# Puedes también examinar los datos con un histograma y un Q-Q plot para comprobar si siguen una distribución normal.
# Winter Nelly
par(mfrow=c(2, 1))
hist(Winter_Nelly, main = "Winter Nelly", xlab = "Peso en gramos")
qqnorm(Winter_Nelly); qqline(Winter_Nelly)
# Golden Bosc
par(mfrow=c(2, 1))
hist(Golden_Bosc, main = "Golden Bosc", xlab = "Peso en gramos")
qqnorm(Golden_Bosc); qqline(Golden_Bosc)
# Prueba de Shapiro-Wilk para comprobar normalidad
print(shapiro.test(Winter_Nelly))
print(shapiro.test(Golden_Bosc))
# Prueba de Levene para comprobar la igualdad de varianzas
leveneTest(Winter_Nelly, Golden_Bosc)
library(car)
# Prueba de Levene para comprobar la igualdad de varianzas
leveneTest(Winter_Nelly, Golden_Bosc)
if (!require ( car )) {
install.packages ("car" , dependencies=TRUE)
require (car)
}
# Importación de las librerias
library(car)
# Prueba de Shapiro-Wilk para comprobar normalidad
print(shapiro.test(Winter_Nelly))
print(shapiro.test(Golden_Bosc))
# Prueba de Levene para comprobar la igualdad de varianzas
leveneTest(Winter_Nelly, Golden_Bosc)
# Combinar los dos vectores en un marco de datos
pesos <- c(Winter_Nelly, Golden_Bosc)
# Crear una variable de grupo
grupo <- c(rep("Winter_Nelly", length(Winter_Nelly)), rep("Golden_Bosc", length(Golden_Bosc)))
# Crear el marco de datos
df <- data.frame(peso = pesos, variedad = grupo)
# Prueba de Levene para comprobar la igualdad de varianzas
leveneTest(peso ~ variedad, data = df)
# Si las suposiciones se mantienen, puedes realizar un test t para muestras independientes.
t.test(Winter_Nelly, Golden_Bosc, var.equal = TRUE)
# Si los datos no siguen una distribución normal o las varianzas no son iguales, puedes utilizar una prueba no paramétrica como la prueba de Mann-Whitney.
wilcox.test(Winter_Nelly, Golden_Bosc)
# Prueba de Shapiro-Wilk para comprobar normalidad
print(shapiro.test(Winter_Nelly))
print(shapiro.test(Golden_Bosc))
# Combinar los dos vectores en un marco de datos
pesos <- c(Winter_Nelly, Golden_Bosc)
# Crear una variable de grupo
grupo <- c(rep("Winter_Nelly", length(Winter_Nelly)), rep("Golden_Bosc", length(Golden_Bosc)))
# Crear el marco de datos
df <- data.frame(peso = pesos, variedad = grupo)
# Prueba de Levene para comprobar la igualdad de varianzas
leveneTest(peso ~ variedad, data = df)
# Si las suposiciones se mantienen, puedes realizar un test t para muestras independientes.
t.test(Winter_Nelly, Golden_Bosc, var.equal = TRUE)
# Si los datos no siguen una distribución normal o las varianzas no son iguales, puedes utilizar una prueba no paramétrica como la prueba de Mann-Whitney.
wilcox.test(Winter_Nelly, Golden_Bosc)
# Si los datos no siguen una distribución normal o las varianzas no son iguales, puedes utilizar una prueba no paramétrica como la prueba de Mann-Whitney.
wilcox.test(Winter_Nelly, Golden_Bosc)
# Transformar los datos utilizando logaritmo
Winter_Nelly_log <- log(Winter_Nelly)
Golden_Bosc_log <- log(Golden_Bosc)
# Graficar los datos transformados
par(mfrow = c(1, 2))
hist(Winter_Nelly_log, main = "Winter Nelly Log-Transformed", xlab = "Log-Weight")
hist(Golden_Bosc_log, main = "Golden Bosc Log-Transformed", xlab = "Log-Weight")
# Verificar la normalidad con la prueba de Shapiro-Wilk
print(shapiro.test(Winter_Nelly_log))
print(shapiro.test(Golden_Bosc_log))
# Si las suposiciones se mantienen, puedes realizar un test t para muestras independientes.
t.test(Winter_Nelly_log, Golden_Bosc_log, var.equal = TRUE)
dir <- "C:/Users/agust/Desktop/Repo IME/IME-2023/EP12"
basename <- "EP11 Datos.csv"
file <- file.path(dir, basename)
poblacion <- read.csv2(file = file)
set.seed(1234)
n <- 500
Ingresos_Media <- select(poblacion %>% filter(educ == "M. Hum. Completa"), contains("ytot"))
if (!require(boot)) {
install.packages("boot", dependencies = TRUE )
require (boot)
}
if (!require(simpleboot)) {
install.packages("simpleboot", dependencies = TRUE )
require (simpleboot)
}
set.seed(1234)
n <- 500
Ingresos_Media <- select(poblacion %>% filter(educ == "M. Hum. Completa"), contains("ytot"))
# Explortacion de las librerias
library(dplyr)
library(ggpubr)
set.seed(1234)
n <- 500
Ingresos_Media <- select(poblacion %>% filter(educ == "M. Hum. Completa"), contains("ytot"))
Ingresos_Tecnico <- select(poblacion %>% filter(educ == "Tecnico Nivel Superior Completo"), contains("ytot") )
Ingresos_Profesional <- select(poblacion %>% filter(educ == "Profesional Completo"), contains("ytot"))
#Se muestrean los ingresos según el nivel de estudios
m_Media <- sample(Ingresos_Media$ytotcorh, n)
m_Tecnico <- sample(Ingresos_Tecnico$ytotcorh, n)
m_Profesional <- sample(Ingresos_Profesional$ytotcorh, n)
# Combinamos los datos en un solo data frame
df <- data.frame(
Ingresos = c(m_Media, m_Tecnico, m_Profesional),
Educacion = factor(c(rep("Media", n), rep("Tecnico", n), rep("Profesional", n)))
)
# Hacemos la prueba de Kruskal-Wallis
kruskal_result <- kruskal.test(Ingresos ~ Educacion, data = df)
print(kruskal_result)
if (!require(FSA)) {
install.packages("FSA", dependencies = TRUE )
require (FSA)
}
# Realizamos la prueba de Dunn post-hoc después de la prueba de Kruskal-Wallis
# Esto nos indicará qué grupos específicos son diferentes entre sí
dunn_result <- dunnTest(df$Ingresos, g=df$Educacion, method="bonferroni")
# Imprimimos los resultados de la prueba de Dunn
print(dunn_result)
# Gráfico QQ para Educación Media
ggplot(df[df$Educacion == "Media",], aes(sample = Ingresos)) +
stat_qq() +
stat_qq_line() +
ggtitle("Gráfico QQ para Ingresos - Educación Media") +
theme_minimal()
# Gráfico QQ para Educación Técnica
ggplot(df[df$Educacion == "Tecnico",], aes(sample = Ingresos)) +
stat_qq() +
stat_qq_line() +
ggtitle("Gráfico QQ para Ingresos - Educación Técnica") +
theme_minimal()
# Gráfico QQ para Educación Profesional
ggplot(df[df$Educacion == "Profesional",], aes(sample = Ingresos)) +
stat_qq() +
stat_qq_line() +
ggtitle("Gráfico QQ para Ingresos - Educación Profesional") +
theme_minimal()
shapiro_test_Media <- shapiro.test(m_Media)
shapiro_test_Tecnico <- shapiro.test(m_Tecnico)
shapiro_test_Profesional <- shapiro.test(m_Profesional)
# Imprimir los resultados de las pruebas de Shapiro-Wilk
print(paste("Test de Shapiro-Wilk para Educación Media: p-value =", shapiro_test_Media$p.value))
print(paste("Test de Shapiro-Wilk para Educación Técnica: p-value =", shapiro_test_Tecnico$p.value))
print(paste("Test de Shapiro-Wilk para Educación Profesional: p-value =", shapiro_test_Profesional$p.value))
# Primero, debemos asegurarnos de que tengamos los paquetes necesarios.
# Si no los tienes instalados, puedes usar install.packages("nombre_del_paquete")
# Para este ejemplo, utilizaremos el conjunto de datos mtcars que viene incorporado en R.
# Este conjunto de datos contiene información sobre diferentes modelos de automóviles.
# Cargamos los datos
data(mtcars)
# Echamos un vistazo a los datos
head(mtcars)
# Vamos a ajustar un modelo lineal simple utilizando la función lm()
# Predeciremos el consumo de millas por galón (mpg) en función de la potencia del motor (hp)
modelo <- lm(mpg ~ hp, data = mtcars)
# Imprimimos un resumen del modelo
summary(modelo)
# Librerías
if (!require(readxl) ) {
install.packages("readxl", dependencies = TRUE )
require (readxl)
}
if (!require(ggpubr) ) {
install.packages("ggpubr", dependencies = TRUE )
require (ggpubr)
}
if (!require(dplyr) ) {
install.packages("dplyr", dependencies = TRUE )
require (dplyr)
}
if (!require(car)){
install.packages("car", dependencies = TRUE )
require (car)
}
if (!require(corrplot)){
install.packages("corrplot", dependencies = TRUE )
require (corrplot)
}
setwd("C:/Users/agust/Desktop/Repo IME/IME-2023/EP14")
data <- read.csv2("EP13 Datos.csv")
data[["id"]] <- factor(1:nrow(data))
# 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito
#    verificador) del integrante de mayor edad del equipo.
set.seed(2704)
# 2.	Seleccionar una muestra de 120 vinos, asegurando que la mitad sean blancos y la otra mitad, tintos. Dividir esta muestra en
#     dos conjuntos: los datos de 80 vinos (40 con clase “Blanco”) para utilizar en la construcción de los modelos y 40 vinos (20 con clase
#     “Blanco”) para poder evaluarlos.
# Separar el data frame en dos: uno para vinos blancos y otro para vinos tintos
vinos_blancos <- data[data$clase == 'Blanco', ]
vinos_tintos <- data[data$clase == 'Tinto', ]
# Seleccionar aleatoriamente 60 vinos de cada tipo
set.seed(2704)  # Asegura que los resultados son reproducibles
vinos_blancos_muestra <- vinos_blancos[sample(nrow(vinos_blancos), 60), ]
vinos_tintos_muestra <- vinos_tintos[sample(nrow(vinos_tintos), 60), ]
# Combinar las dos muestras en un solo data frame
muestra <- rbind(vinos_blancos_muestra, vinos_tintos_muestra)
# Dividir la muestra en un conjunto de entrenamiento y uno de prueba
muestra_entrenamiento <- muestra[sample(nrow(muestra), 80), ]
muestra_prueba <- muestra[-row.names(muestra_entrenamiento), ]
# Seleccionar aleatoriamente 60 vinos de cada tipo
set.seed(2704)  # Asegura que los resultados son reproducibles
vinos_blancos_muestra <- vinos_blancos[sample(nrow(vinos_blancos), 60), ]
vinos_tintos_muestra <- vinos_tintos[sample(nrow(vinos_tintos), 60), ]
# Combinar las dos muestras en un solo data frame
muestra <- rbind(vinos_blancos_muestra, vinos_tintos_muestra)
# Dividir la muestra en un conjunto de entrenamiento y uno de prueba
muestra_entrenamiento <- muestra[sample(nrow(muestra), 80), ]
# Conviertir los nombres de las filas a numéricos
indices_entrenamiento <- as.numeric(row.names(muestra_entrenamiento))
# Excluir las filas de entrenamiento
muestra_prueba <- muestra[-indices_entrenamiento, ]
View(muestra_prueba)
# 3. Seleccionar 6 variables predictoras de manera aleatoria (al igual que en el ejercicio anterior).
# Se extraen de forma aleatoria las variables para la prueba
opciones <-  c("clase", "acidez.fija", "acidez.volatil", "acido.citrico",
"azucar.residual", "cloruros", "dioxido.azufre.libre", "dioxido.azufre.total",
"densidad", "ph", "sulfatos", "alcohol")
variables <- sample(opciones, 6)
print(variables)
# Seleccionar la variable 'alcohol' porque se considera que los vinos con un mayor contenido de alcohol suelen ser de mayor calidad.
variables <- c(variables, "alcohol")
print(variables)
calidad <- muestra_prueba[["calidad"]]
# Se analiza la correlación existente entre las variables no seleccionadas
acidesFija <- muestra_prueba[["acidez.fija"]]
acidesVolatil <- muestra_prueba[["acidez.volatil"]]
acidoCitrico <- muestra_prueba[["acido.citrico"]]
dioxidoAzufreLibre <- muestra_prueba[["dioxido.azufre.libre"]]
densidad <- muestra_prueba[["densidad"]]
alcohol <- muestra_prueba[["alcohol"]]
correlacion_lineal <- cor(acidesFija, calidad)
cat("Acides fija: ", correlacion_lineal, "\n")
correlacion_lineal <- cor(acidesVolatil, calidad)
cat("Acides Volatil: ", correlacion_lineal, "\n")
correlacion_lineal <- cor(acidoCitrico, calidad)
cat("Acido citrico: ", correlacion_lineal, "\n")
correlacion_lineal <- cor(dioxidoAzufreLibre, calidad)
cat("dioxido azufre libre: ", correlacion_lineal, "\n")
correlacion_lineal <- cor(densidad, calidad)
cat("Densidad: ", correlacion_lineal, "\n")
correlacion_lineal <- cor(alcohol, calidad)
cat("Alcohol: ", correlacion_lineal, "\n")
# Asegurarse de que la variable de destino es un factor
muestra_entrenamiento$clase <- as.factor(muestra_entrenamiento$clase)
# Crear el modelo de regresión logística
modelo <- glm(clase ~ alcohol, data = muestra_entrenamiento, family = binomial)
# Resumen del modelo
summary(modelo)
